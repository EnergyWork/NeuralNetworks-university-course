{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2. Модели представления текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, os, string, re, copy, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\artem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\artem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_DEFAULT = 'utf-8'\n",
    "TRAIN_FILE = 'train.json'\n",
    "TEST_FILE = 'test.json'\n",
    "PRECISION = 4 # the number of signs after the comma\n",
    "\n",
    "ID = 'id'\n",
    "TEXT = 'text'\n",
    "SENTIMENT = 'sentiment'\n",
    "SENTIMENTS = ['negative', 'positive', 'neutral']\n",
    "POSITIVE = 0\n",
    "NEGATIVE = 1\n",
    "NEUTRAL = 2\n",
    "\n",
    "ORIGIN_WORD = 'OriginWord'\n",
    "NORMAL_FORM = 'NormalForm'\n",
    "POS = 'POS'\n",
    "CASE = 'Case'\n",
    "GENDER = 'Gender'\n",
    "DICT_EXIST = 'FromDict'\n",
    "WORDS = \"Words\"\n",
    "FREQ = \"Freq\"\n",
    "UNIQ = \"uniquies\"\n",
    "COUNT = \"count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = {\n",
    "    \"NOUN\":\"имя существительное\",\n",
    "    \"ADJF\": \"имя прилагательное (полное)\",\n",
    "    \"NOUN\":\"имя существительное\",\n",
    "    \"ADJF\":\"имя прилагательное (полное)\",\n",
    "    \"ADJS\":\"имя прилагательное (краткое)\",\n",
    "    \"COMP\":\"компаратив\",\n",
    "    \"VERB\":\"глагол (личная форма)\",\n",
    "    \"INFN\":\"глагол (инфинитив)\",\n",
    "    \"PRTF\":\"причастие (полное)\",\n",
    "    \"PRTS\":\"причастие (краткое)\",\n",
    "    \"GRND\":\"деепричастие\",\n",
    "    \"NUMR\":\"числительное\",\n",
    "    \"ADVB\":\"наречие\",\n",
    "    \"NPRO\":\"местоимение-существительное\",\n",
    "    \"PRED\":\"предикатив\",\n",
    "    \"PREP\":\"предлог\",\n",
    "    \"CONJ\":\"союз\",\n",
    "    \"PRCL\":\"частица\",\n",
    "    \"INTJ\":\"междометие\",\n",
    "    \"nomn\":\"именительный\",\n",
    "    \"gent\":\"родительный\",\n",
    "    \"datv\":\"дательный\",\n",
    "    \"accs\":\"винительный\",\n",
    "    \"ablt\":\"творительный\",\n",
    "    \"loct\":\"предложный\",\n",
    "    \"voct\":\"звательный\",\n",
    "    \"gen2\":\"второй родительный (частичный)\",\n",
    "    \"acc2\":\"второй винительный\",\n",
    "    \"loc2\":\"второй предложный (местный)\",\n",
    "    \"masc\":\"мужской род\",\n",
    "    \"femn\":\"женский род\",\n",
    "    \"neut\":\"средний род\",\n",
    "    \"LATN\":\"Токен состоит из латинских букв (например, “foo-bar” или “Maßstab”)\",\n",
    "    \"PNCT\":\"Пунктуация (например, , или !? или …)\",\n",
    "    \"NUMB\":\"Число (например, “204” или “3.14”)\",\n",
    "    \"intg\":\"целое число (например, “204”)\",\n",
    "    \"real\":\"вещественное число (например, “3.14”)\",\n",
    "    \"ROMN\":\"Римское число (например, XI)\",\n",
    "    \"UNKN\":\"Токен не удалось разобрать\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Подготовка текстового корпуса\n",
    "- Прочитайте описание задачи Sentiment analysis: https://www.kaggle.com/c/sentiment-analysis-in-russian.\n",
    "- Скачайте файлы `train.json` и `test.json`: https://www.kaggle.com/c/sentiment-analysis-in-russian/data.\n",
    "- Загрузите в ноутбук скачанные файлы, выведите информацию по ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    start = time.perf_counter()\n",
    "    with open(filename, 'r', encoding=ENCODING_DEFAULT) as file:\n",
    "        data = json.load(file)\n",
    "    print(\"[INFO]: read time: %0.4f sec\" % (time.perf_counter() - start))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_file_description(data, train=False):\n",
    "    '''размер файла, количество текстов, средняя/макс./мин. длина текста, распределение тональности для обучающей выборки'''\n",
    "    text_lens = []\n",
    "    if train:\n",
    "        sentiments = dict.fromkeys(SENTIMENTS, 0)\n",
    "    for news in data:\n",
    "        if train:\n",
    "            sentiments[news[SENTIMENT]] += 1\n",
    "        text_lens.append(len(news[TEXT]))\n",
    "    print(\"Размер(байты):\", os.path.getsize(TRAIN_FILE if train else TEST_FILE))\n",
    "    print(\"Количество примеров:\", len(data))\n",
    "    print(\"Средняя длина текста:\", np.mean(text_lens))\n",
    "    print(\"Максимальная длина текста:\", np.max(text_lens))\n",
    "    print(\"Минимальная длина текста:\", np.min(text_lens))\n",
    "    if train:\n",
    "        print(\"Распределение тональностей:\")\n",
    "        print(\"\\tПозитивных:\", sentiments[SENTIMENTS[POSITIVE]])\n",
    "        print(\"\\tНегативных:\", sentiments[SENTIMENTS[NEGATIVE]])\n",
    "        print(\"\\tНейтральных:\", sentiments[SENTIMENTS[NEUTRAL]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: read time: 0.4575 sec\n",
      "Размер(байты): 59298269\n",
      "Количество примеров: 8263\n",
      "Средняя длина текста: 3911.85017548106\n",
      "Максимальная длина текста: 381498\n",
      "Минимальная длина текста: 28\n",
      "Распределение тональностей:\n",
      "\tПозитивных: 1434\n",
      "\tНегативных: 2795\n",
      "\tНейтральных: 4034\n"
     ]
    }
   ],
   "source": [
    "train_json = read_json(TRAIN_FILE)\n",
    "print_file_description(train_json, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: read time: 0.1556 sec\n",
      "Размер(байты): 15417058\n",
      "Количество примеров: 2056\n",
      "Средняя длина текста: 4102.4143968871595\n",
      "Максимальная длина текста: 320754\n",
      "Минимальная длина текста: 35\n"
     ]
    }
   ],
   "source": [
    "test_json = read_json(TEST_FILE)\n",
    "print_file_description(test_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Булевская модель\n",
    "Напишите функцию `get_bool_model()` на входе которой текстовый корпус, на выходе – булевская матрица термин-документ.\n",
    "\n",
    "В функции должны осуществляться следующие действия:\n",
    "- все слова преобразуются в нормальную форму;\n",
    "- удаляются стоп-слова;\n",
    "- удаляются (или оставляются) слова заданных частей речи (список частей речи должен передаваться в виде параметра);\n",
    "- удаляются слова, частотность которых во всем корпусе ниже заданного порога (параметр);\n",
    "- создается словарь корпуса.\n",
    "\n",
    "Нельзя использовать библиотечные функции `scikit-learn`.  \n",
    "Можно использовать функции, разработанные в этой и предыдущей лабораторных работах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return super().default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "nlp = word_tokenize\n",
    "\n",
    "stopwords_dict = Counter(stopwords.words('russian')) # {\"sw1\" : 1, \"sw2\" : 1, ..., \"swN\" : 1}\n",
    "re_numbers_pattern = re.compile(r\"\\d+([,\\.]\\d+){0,}\") # https://regex101.com/r/1V0HDV/1\n",
    "re_spaces_pattern = re.compile(r\"\\s{2,}\") # two or more spaces\n",
    "re_newline_pattern = re.compile(r\"\\n\") # newline\n",
    "\n",
    "def save_data(data, filename='tmp'):\n",
    "    with open(f\"{filename}.json\", \"w+\", encoding='utf-8') as f:\n",
    "        tojs = json.dumps(data, indent=4, ensure_ascii=False, cls=SetEncoder)\n",
    "        f.write(tojs)\n",
    "\n",
    "def get_data(t):\n",
    "    return 'None' if t is None else t\n",
    "\n",
    "def check_word(word):\n",
    "    # token filter\n",
    "    if word not in string.punctuation and \\\n",
    "        len(re.findall(re_numbers_pattern, word)) == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def text_prepare(text):\n",
    "    # replace '\\n' on ' ', '<spaces>' on '<space>'\n",
    "    text = re.sub(re_newline_pattern, ' ', text)\n",
    "    text = re.sub(re_spaces_pattern, ' ', text)\n",
    "    return text\n",
    "\n",
    "def parse_text(text):\n",
    "    ret = []\n",
    "    tokens = nlp(text_prepare(text))\n",
    "    for word in tokens:\n",
    "        if check_word(word):\n",
    "            parsed = morph.parse(word)[0]\n",
    "            data = {\n",
    "                ORIGIN_WORD : word,\n",
    "                NORMAL_FORM : parsed.normal_form,\n",
    "                POS         : parsed.tag.POS if parsed.tag.POS is not None else 'NOUN',\n",
    "                CASE        : parsed.tag.case,\n",
    "                GENDER      : parsed.tag.gender,\n",
    "                DICT_EXIST  : parsed.is_known,\n",
    "            }\n",
    "            ret.append(data)              \n",
    "    return ret\n",
    "\n",
    "def get_dictionary(parsed):\n",
    "    tmp = {}\n",
    "    for value in parsed:\n",
    "        if tmp.get(value[NORMAL_FORM]) is None:\n",
    "            tmp.update({\n",
    "            value[NORMAL_FORM] : { \n",
    "                POS   : value[POS], \n",
    "                WORDS : set(([value[ORIGIN_WORD]])),\n",
    "                FREQ : 1,\n",
    "            }})\n",
    "        else:\n",
    "            tmp[value[NORMAL_FORM]][WORDS].add(value[ORIGIN_WORD])\n",
    "            tmp[value[NORMAL_FORM]][FREQ] += 1  \n",
    "    return tmp\n",
    "\n",
    "def clearing(data, freq_rm, pos_rm):\n",
    "    tmp = {}\n",
    "    print(\"[INFO]: lenght of corpus dictionary befor clearing:\", len(data))\n",
    "    for key, val in data.items():\n",
    "        if not (val[POS] in pos_rm or val[FREQ] < freq_rm or key in stopwords_dict):\n",
    "            tmp.update({key : val})\n",
    "    print(\"[INFO]: lenght of corpus dictionary after clearing:\", len(tmp))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa ff v ffg sdfsf fff fsfsfsf fsd g 123 fsdf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'aaa ff v    ffg\\nsdfsf fff \\n   fsfsfsf fsd g 123 fsdf'\n",
    "text_prepare(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bool_model(corpus, freq_remove=0, pos_remove=[]):\n",
    "    parsed_texts = [] # to store the parsed texts\n",
    "    documents_dicts = [] # list of dicts of texts\n",
    "\n",
    "    # loop by corpus elements\n",
    "    for text in corpus:\n",
    "        parsed = parse_text(text[TEXT]) # text morph analysis\n",
    "        parsed_texts.extend(parsed) # adding to list of all parsed texts\n",
    "        documents_dicts.append(get_dictionary(parsed)) # forming dictionary of text and adding to list\n",
    "    corpus_dict = get_dictionary(parsed_texts)\n",
    "    \n",
    "    #save_data(corpus_dict) #todo delete\n",
    "\n",
    "    # clearing the text from stopwords, low-frequency and exclude some pos\n",
    "    corpus_dict_cleared = clearing(corpus_dict, freq_remove, pos_remove)\n",
    "\n",
    "    # forming term matrix\n",
    "    term_matrix = []\n",
    "    for word in corpus_dict_cleared:\n",
    "        word_exist = []\n",
    "        for doc_dict in documents_dicts:\n",
    "            word_exist.append(True if word in doc_dict else False)\n",
    "        term_matrix.append(word_exist)\n",
    "        \n",
    "    return term_matrix, corpus_dict_cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: lenght of corpus dictionary befor clearing: 662\n",
      "[INFO]: lenght of corpus dictionary after clearing: 294\n",
      "\n",
      "Матрица термин-документ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>досудебный</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>начать</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>национальный</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сообщить</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>финансовый</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>формировать</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сохраниться</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>модельный</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>зависеть</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>признать</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2\n",
       "досудебный     True   True  False\n",
       "начать         True   True  False\n",
       "национальный   True  False  False\n",
       "сообщить       True   True  False\n",
       "финансовый     True  False  False\n",
       "...             ...    ...    ...\n",
       "формировать   False  False   True\n",
       "сохраниться   False  False   True\n",
       "модельный     False  False   True\n",
       "зависеть      False  False   True\n",
       "признать      False  False   True\n",
       "\n",
       "[294 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_model, dict_cleared = get_bool_model(train_json[:3], freq_remove=1, pos_remove=['NOUN'])\n",
    "df = pd.DataFrame(bool_model, index=dict_cleared.keys())\n",
    "df.to_csv(\"bool_model.csv\")\n",
    "print(\"\\nМатрица термин-документ\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Модель TF-IDF\n",
    "Напишите функцию `get_tfidf_model()` на входе которой текстовый корпус, на выходе – матрица термин-документ c TF-IDF-весами.\n",
    "\n",
    "В функции должны осуществляться следующие действия:\n",
    "- все слова преобразуются в нормальную форму;\n",
    "- удаляются стоп-слова;\n",
    "- удаляются (или оставляются) слова заданных частей речи (список частей речи должен передаваться в виде параметра);\n",
    "- удаляются слова, частотность которых во всем корпусе ниже заданного порога (параметр);\n",
    "- создается словарь корпуса;\n",
    "- вычисляются глобальные IDF-веса и сохраняются в словарь;\n",
    "- слова для документов взвешиваются в соответствии со схемой TF-IDF.\n",
    "\n",
    "Нельзя использовать библиотечные функции `scikit-learn`.  \n",
    "Можно использовать функции, разработанные в предыдущей лабораторной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(documents_dict):\n",
    "\n",
    "    def compute_tf(document):\n",
    "        tf_text = {k : v[FREQ] for k, v in document.items()}\n",
    "        for word in tf_text:\n",
    "            tf_text[word] = tf_text[word] / float(len(document))\n",
    "        return tf_text\n",
    "\n",
    "    def compute_idf(word, documents_dict):\n",
    "        return np.log(1+(len(documents_dict) / sum([1.0 for doc in documents_dict if word in doc])))\n",
    "\n",
    "    documents_list = []\n",
    "    for document in documents_dict:\n",
    "        tf_idf_dictionary = {}\n",
    "        computed_tf = compute_tf(document)\n",
    "        for word in computed_tf:\n",
    "            tf_idf_dictionary[word] = computed_tf[word] * compute_idf(word, documents_dict)\n",
    "        documents_list.append(tf_idf_dictionary)\n",
    "\n",
    "    return documents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# начало такое же\n",
    "def get_tfidf_model(corpus, freq_remove=0, pos_remove=[]):\n",
    "    parsed_texts = [] # to store the parsed texts\n",
    "    documents_dicts = [] # list of dicts of texts\n",
    "\n",
    "    # loop by corpus elements\n",
    "    for text in corpus:\n",
    "        parsed = parse_text(text[TEXT]) # text morph analysis\n",
    "        parsed_texts.extend(parsed) # adding to list of all parsed texts\n",
    "        documents_dicts.append(clearing(get_dictionary(parsed), freq_remove, pos_remove)) # forming dictionary of text and adding to list\n",
    "    corpus_dict = get_dictionary(parsed_texts)\n",
    "    \n",
    "    # clearing the text from stopwords, low-frequency and exclude some pos\n",
    "    corpus_dict_cleared = clearing(corpus_dict, freq_remove, pos_remove)\n",
    "\n",
    "    tfidf_dict = compute_tfidf(documents_dicts)\n",
    "\n",
    "    texts = []\n",
    "    for clear_document_dict in documents_dicts:\n",
    "      tmp_text = []\n",
    "      for word in clear_document_dict:\n",
    "        for _ in range(clear_document_dict[word][FREQ]):\n",
    "          tmp_text.append(word)\n",
    "      texts.append(' '.join(tmp_text))\n",
    "\n",
    "      #norm L2\n",
    "      tfidf_dict_norm = []\n",
    "      for tfidf_doc in tfidf_dict:\n",
    "        sum_of_squares = sum([x**2 for x in tfidf_doc.values()])\n",
    "        for w, f in tfidf_doc.items():\n",
    "          tfidf_doc[w] /= math.sqrt(sum_of_squares)\n",
    "        tfidf_dict_norm.append(tfidf_doc)\n",
    "        \n",
    "        \n",
    "    return tfidf_dict_norm, corpus_dict_cleared, texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте матрицу термин-документ для текстовых корпусов из первого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: lenght of corpus dictionary befor clearing: 110\n",
      "[INFO]: lenght of corpus dictionary after clearing: 94\n",
      "[INFO]: lenght of corpus dictionary befor clearing: 135\n",
      "[INFO]: lenght of corpus dictionary after clearing: 119\n",
      "[INFO]: lenght of corpus dictionary befor clearing: 489\n",
      "[INFO]: lenght of corpus dictionary after clearing: 437\n",
      "[INFO]: lenght of corpus dictionary befor clearing: 211\n",
      "[INFO]: lenght of corpus dictionary after clearing: 192\n",
      "[INFO]: lenght of corpus dictionary befor clearing: 800\n",
      "[INFO]: lenght of corpus dictionary after clearing: 744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>досудебный</th>\n",
       "      <td>0.096895</td>\n",
       "      <td>0.043312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>расследование</th>\n",
       "      <td>0.096895</td>\n",
       "      <td>0.043312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>факт</th>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>покупка</th>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>енпф</th>\n",
       "      <td>0.283898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>пакет</th>\n",
       "      <td>0.070975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>облигация</th>\n",
       "      <td>0.070975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>тоо</th>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>``</th>\n",
       "      <td>0.283898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>бузгул</th>\n",
       "      <td>0.070975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3\n",
       "досудебный     0.096895  0.043312  0.000000  0.000000\n",
       "расследование  0.096895  0.043312  0.000000  0.000000\n",
       "факт           0.074730  0.033404  0.008637  0.000000\n",
       "покупка        0.048448  0.000000  0.022397  0.000000\n",
       "енпф           0.283898  0.000000  0.000000  0.000000\n",
       "пакет          0.070975  0.000000  0.000000  0.000000\n",
       "облигация      0.070975  0.000000  0.000000  0.000000\n",
       "тоо            0.048448  0.000000  0.000000  0.078577\n",
       "``             0.283898  0.000000  0.000000  0.000000\n",
       "бузгул         0.070975  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model, corpus_dict, texts = get_tfidf_model(train_json[:4], freq_remove=0, pos_remove=[])\n",
    "df = pd.DataFrame(tfidf_model).fillna(0)\n",
    "df.to_csv(\"tfidf_model.csv\")\n",
    "df.T[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните результаты работы вашей функции (полученные веса) с результатами работы класса [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) из `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1448: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(smooth_idf = False, tokenizer = word_tokenize, vocabulary = corpus_dict.keys())\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>досудебный</th>\n",
       "      <td>0.093068</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>расследование</th>\n",
       "      <td>0.093068</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>факт</th>\n",
       "      <td>0.070781</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>покупка</th>\n",
       "      <td>0.046534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>енпф</th>\n",
       "      <td>0.262338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>пакет</th>\n",
       "      <td>0.065584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>облигация</th>\n",
       "      <td>0.065584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>тоо</th>\n",
       "      <td>0.046534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>``</th>\n",
       "      <td>0.524676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>бузгул</th>\n",
       "      <td>0.065584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3\n",
       "досудебный     0.093068  0.044753  0.000000  0.000000\n",
       "расследование  0.093068  0.044753  0.000000  0.000000\n",
       "факт           0.070781  0.034036  0.008775  0.000000\n",
       "покупка        0.046534  0.000000  0.023076  0.000000\n",
       "енпф           0.262338  0.000000  0.000000  0.000000\n",
       "пакет          0.065584  0.000000  0.000000  0.000000\n",
       "облигация      0.065584  0.000000  0.000000  0.000000\n",
       "тоо            0.046534  0.000000  0.000000  0.077358\n",
       "``             0.524676  0.000000  0.000000  0.000000\n",
       "бузгул         0.065584  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X.toarray().T\n",
    "df = pd.DataFrame(data=data, index=list(corpus_dict.keys()))\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Модель word2vec\n",
    "Напишите функцию `get_word2vec_model()` на входе которой текстовый корпус и модель `word2vec`, на выходе – матрица термин-документ c word2vec-весами.\n",
    "\n",
    "В функции должны осуществляться следующие действия:\n",
    "- все слова преобразуются в нормальную форму (при необходимости – в зависимости от используемой модели);\n",
    "- удаляются стоп-слова;\n",
    "- удаляются (или оставляются) слова заданных частей речи (список частей речи должен передаваться в виде параметра);\n",
    "- удаляются слова, частотность которых во всем корпусе ниже заданного порога (параметр);\n",
    "- создается словарь корпуса;\n",
    "- вычисляются веса word2vec для заданной модели.\n",
    "\n",
    "\n",
    "Можно использовать библиотечные функции и функции, разработанные в лабораторных работах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_model():\n",
    "    # Ваш код здесь\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте матрицу термин-документ для текстовых корпусов из первого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
